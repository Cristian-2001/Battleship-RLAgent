# ğŸš¢ Battleship Agent

A reinforcement learning agent trained to play Battleship using Q-learning.

## ğŸ¯ Overview

This project implements an intelligent Battleship agent that learns to play optimally through Q-learning. The agent can play against other agents or human players using a tuple space communication system.

## ğŸ—ï¸ Architecture

### Core Classes
- **ğŸš¢ Ship**: Represents individual ships with hit tracking and positioning
- **âš”ï¸ Battleship**: Game environment managing grids, ships, and actions
- **ğŸ¤– BattleshipAgent**: AI agent with Q-learning capabilities and communication

### Key Features
- **ğŸ“Š Q-learning**: Epsilon-greedy policy with experience-based learning
- **ğŸ”„ Multi-agent**: Two agents communicate via tuple space
- **ğŸ‘¤ Human vs AI**: Interactive gameplay option
- **ğŸ“ˆ Training**: 40,000 episodes with reward optimization

## ğŸ® Game Parameters

- **Grid Size**: 4x4 (expandable to 7x7)
- **Ships**: Multiple ships with no diagonal contact
- **Rewards**: Hit (+150), Sunk (+30), Win (+1030)
- **Penalties**: Miss (-25), Already hit (-200), Turn (-50)

## ğŸš€ Training Results

The agent achieved improved performance through:
- âœ… Increased training episodes (40K)
- âœ… Optimized reward structure
- âœ… Enhanced penalty system
- âœ… Consecutive hit/miss handling

## ğŸ”§ Usage

Agents communicate through tuple space messages:
- `("Request", counter, x, y)` - Attack request
- `("Response", counter, x, y, value)` - Attack result
- `("Game over", counter, result)` - Game end signal

## ğŸ¯ Future Improvements

- ğŸ” Efficiency optimization for larger grids
- ğŸ“š Better Q-table representation
- ğŸ² Enhanced ship positioning strategies
- ğŸ¨ Improved human vs agent interface

---

*Developed by Casali Cristian for the course of Distributed Artificial Intelligence, feb 2025*
